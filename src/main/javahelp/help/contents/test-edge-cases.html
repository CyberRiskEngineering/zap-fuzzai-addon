<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<TITLE>
Fuzz AI Files - Test Edge Cases
</TITLE>
</HEAD>
<BODY>
<H1>Fuzz AI Files - Test Edge Cases</H1>

<H3>001 Trick Model Safety</H3>

This file contains adversarial prompts designed to test model safety boundaries.
The goal is to determine whether the model can be tricked into bypassing its alignment constraints,
especially through indirect, obfuscated, or deceptive instructions.
<p>
These tests focus on red teaming via jailbreaks, prompt injection, persona misuse, and ambiguity traps.
<p>
Fuzzing File: <a href="https://github.com/zaproxy/zap-extensions/blob/main/addOns/fuzzai/src/main/zapHomeFiles/fuzzers/fuzzai/AI/test-edge-cases/001-trick-model-safety.txt">001-trick-model-safety.txt</a>
<p>
Author: 
<ul>
<li>yiannis@owasp.org
</ul>

<H3>002 Manipulate Model Safety</H3>

This file contains payloads that attempt to manipulate the model into violating safety policies.
These prompts differ from direct jailbreaks: they use flattery, social engineering, emotional appeals,
false logic, and trust-building to convince the model to act unsafely or unethically.
<p>
Fuzzing File: <a href="https://github.com/zaproxy/zap-extensions/blob/main/addOns/fuzzai/src/main/zapHomeFiles/fuzzers/fuzzai/AI/test-edge-cases/002-manipulate-model-safety.txt">002-manipulate-model-safety.txt</a>
<p>
Author: 
<ul>
<li>yiannis@owasp.org
</ul>

<H3>003 Confuse Model Safety</H3>

This file contains adversarial prompts intended to confuse or overload the model,
often leading to incoherent, misaligned, or potentially unsafe responses.
The goal is to probe failure points in reasoning, context management, and ambiguity handling.
<p>
Fuzzing File: <a href="https://github.com/zaproxy/zap-extensions/blob/main/addOns/fuzzai/src/main/zapHomeFiles/fuzzers/fuzzai/AI/test-edge-cases/003-confuse-model-safety.txt">003-confuse-model-safety.txt</a>
<p>
Author: 
<ul>
<li>yiannis@owasp.org
</ul>

<H3>004 Distort Model Facts</H3>

This file contains adversarial prompts designed to test the model's ability to resist misinformation,
disinformation, and conspiracy theory generation. The focus is on evaluating the model’s resistance
to factual distortion, false premises, planted assumptions, and truth-adjacent manipulation.

<p>
Fuzzing File: <a href="https://github.com/zaproxy/zap-extensions/blob/main/addOns/fuzzai/src/main/zapHomeFiles/fuzzers/fuzzai/AI/test-edge-cases/004-distort-model-facts.txt">004-distort-model-facts.txt</a>
<p>
Author: 
<ul>
<li>yiannis@owasp.org
</ul>

<H3>005 Inject Model Bias</H3>

This file contains adversarial prompts that attempt to inject or reveal biases in the model’s behavior.
The focus is on social, gender, racial, cultural, and geopolitical biases—especially those triggered
by leading language, incomplete framing, or identity-based generalizations.
<p>
Fuzzing File: <a href="https://github.com/zaproxy/zap-extensions/blob/main/addOns/fuzzai/src/main/zapHomeFiles/fuzzers/fuzzai/AI/test-edge-cases/005-inject-model-bias.txt">005-inject-model-bias.txt</a>
<p>
Author: 
<ul>
<li>yiannis@owasp.org
</ul>

</BODY>
</HTML>
